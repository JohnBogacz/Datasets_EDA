{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import statsmodels as sm\n",
    "# import xgboost as xgb\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import (\n",
    "    OrdinalEncoder\n",
    ")\n",
    "from sklearn.decomposition import (\n",
    "    PCA\n",
    ")\n",
    "from sklearn.pipeline import (\n",
    "    Pipeline,\n",
    "    make_pipeline,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (A) Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/school/Documents/repositories/Datasets_EDA/src/Allstate Claims Severity/code/v2\n",
      "/Users/school/Documents/repositories/Datasets_EDA/src/Allstate Claims Severity/\n"
     ]
    }
   ],
   "source": [
    "PATH = os.getcwd()\n",
    "print(PATH)\n",
    "PATH = PATH.split('/')[:-2]\n",
    "PATH = ''.join([str(folder + '/') for folder in PATH])\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1\n",
    "\n",
    "*'train.csv'* file does go on longer then line 188,320. But there appears to be some formatting issue after that line. I tried to write a separate python file that can add line by line of *'train.csv'* into a Panda's Dataframe but that seem to take to long. So I'll use up to 188,320 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "    filepath_or_buffer= os.path.join(PATH, 'train.csv'),\n",
    "    on_bad_lines= 'skip' # issue on line 188320\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   id      cat1      cat2      cat3      cat4      cat5  \\\n",
      "188317  587633.000000         B         A         A         B         A   \n",
      "188318       0.348388   .672862   .551054   .344450   .447670   .538810   \n",
      "\n",
      "            cat6      cat7      cat8      cat9  ...     cont6     cont7  \\\n",
      "188317         A         A         A         A  ...  0.844563  0.533048   \n",
      "188318   .492200   .481306   .654753   .406237  ...       NaN       NaN   \n",
      "\n",
      "          cont8    cont9   cont10    cont11    cont12    cont13   cont14  \\\n",
      "188317  0.97123  0.93383  0.83814  0.932195  0.946432  0.810511  0.72146   \n",
      "188318      NaN      NaN      NaN       NaN       NaN       NaN      NaN   \n",
      "\n",
      "           loss  \n",
      "188317  4751.72  \n",
      "188318      NaN  \n",
      "\n",
      "[2 rows x 132 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.iloc[188317:188319]) # need to drop 188318 as it doesn't fit with data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont6  \\\n",
      "188317  587633.0    B    A    A    B    A    A    A    A    A  ...  0.844563   \n",
      "\n",
      "           cont7    cont8    cont9   cont10    cont11    cont12    cont13  \\\n",
      "188317  0.533048  0.97123  0.93383  0.83814  0.932195  0.946432  0.810511   \n",
      "\n",
      "         cont14     loss  \n",
      "188317  0.72146  4751.72  \n",
      "\n",
      "[1 rows x 132 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df.drop(\n",
    "    inplace= True,\n",
    "    index= 188318,\n",
    "    axis= 'index'\n",
    ")\n",
    "print(train_df.iloc[188317:188319]) # need to drop 188318 as it doesn't fit with data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2\n",
    "\n",
    "Combine rest of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file= os.path.join(PATH, 'train.csv'), mode= 'r', newline= '\\n') as f:\n",
    "    file_reminder = list()\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        if i < 188320 or i % 2 == 0:\n",
    "            continue\n",
    "        \n",
    "        new_line: list[str] = line.split(',')[:-1]\n",
    "        new_line = [s.replace(' ','') for s in new_line] \n",
    "        new_line = [s.replace(',','') for s in new_line]\n",
    "        file_reminder.append(new_line)\n",
    "\n",
    "    temp_df = pd.DataFrame(\n",
    "        data= file_reminder,\n",
    "        columns= train_df.columns\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...    cont6  \\\n",
      "0     567844    B    A    A    A    A    B    A    A    A  ...  .904450   \n",
      "1     567845    A    B    B    A    A    A    A    A    B  ...  .470691   \n",
      "2     567847    A    B    A    A    A    A    A    A    B  ...  .741088   \n",
      "3     567848    A    B    A    A    B    A    A    A    B  ...  .456654   \n",
      "4     567854    B    A    A    B    A    B    A    A    A  ...  .499177   \n",
      "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...      ...   \n",
      "6269  587620    A    B    A    A    A    A    A    A    B  ...  .242437   \n",
      "6270  587624    A    A    A    A    A    B    A    A    A  ...  .334270   \n",
      "6271  587630    A    B    A    A    A    A    A    B    B  ...  .345883   \n",
      "6272  587632    A    B    A    A    A    A    A    A    B  ...  .704364   \n",
      "6273  587633    B    A    A    B    A    A    A    A    A  ...  .844563   \n",
      "\n",
      "        cont7    cont8    cont9   cont10   cont11   cont12   cont13   cont14  \\\n",
      "0     .633885  .829390  .969090  .828890  .797841  .843026  .854872  .313554   \n",
      "1     .654134  .417620  .394470  .433730  .484404  .473688  .290422  .205698   \n",
      "2     .575572  .662010  .583250  .428280  .569745  .594646  .770888  .487595   \n",
      "3     .423280  .360830  .468530  .516660  .805285  .793317  .363547  .254809   \n",
      "4     .443760  .435180  .662010  .577160  .644013  .630853  .354344  .391750   \n",
      "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "6269  .289949  .245640  .308590  .329350  .223038  .220003  .333292  .208216   \n",
      "6270  .382000  .634750  .404550  .477790  .307628  .301921  .318646  .305872   \n",
      "6271  .370534  .245640  .458080  .477790  .445614  .443374  .339244  .503888   \n",
      "6272  .562866  .349870  .447670  .538810  .863052  .852865  .654753  .721707   \n",
      "6273  .533048  .971230  .933830  .838140  .932195  .946432  .810511  .721460   \n",
      "\n",
      "         loss  \n",
      "0      492.93  \n",
      "1     8930.79  \n",
      "2     1796.58  \n",
      "3     1167.70  \n",
      "4      789.59  \n",
      "...       ...  \n",
      "6269  1198.62  \n",
      "6270  1108.34  \n",
      "6271  5762.64  \n",
      "6272  1562.87  \n",
      "6273  4751.72  \n",
      "\n",
      "[6274 rows x 132 columns]\n"
     ]
    }
   ],
   "source": [
    "print(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= pd.concat(\n",
    "    objs=[train_df, temp_df]\n",
    ")\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont6  \\\n",
      "0        1.0    A    B    A    B    A    A    A    A    B  ...  0.718367   \n",
      "1        2.0    A    B    A    A    A    A    A    A    B  ...  0.438917   \n",
      "2        5.0    A    B    A    A    B    A    A    A    B  ...  0.289648   \n",
      "3       10.0    B    B    A    B    A    A    A    A    B  ...  0.440945   \n",
      "4       11.0    A    B    A    B    A    A    A    A    B  ...  0.178193   \n",
      "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
      "6269  587620    A    B    A    A    A    A    A    A    B  ...   .242437   \n",
      "6270  587624    A    A    A    A    A    B    A    A    A  ...   .334270   \n",
      "6271  587630    A    B    A    A    A    A    A    B    B  ...   .345883   \n",
      "6272  587632    A    B    A    A    A    A    A    A    B  ...   .704364   \n",
      "6273  587633    B    A    A    B    A    A    A    A    A  ...   .844563   \n",
      "\n",
      "         cont7    cont8    cont9   cont10    cont11    cont12    cont13  \\\n",
      "0      0.33506   0.3026  0.67135   0.8351  0.569745  0.594646  0.822493   \n",
      "1     0.436585  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431   \n",
      "2     0.315545   0.2732  0.26076  0.32446  0.381398  0.373424  0.195709   \n",
      "3     0.391128  0.31796  0.32128  0.44467  0.327915   0.32157  0.605077   \n",
      "4     0.247408  0.24564  0.22089   0.2123  0.204687  0.202213  0.246011   \n",
      "...        ...      ...      ...      ...       ...       ...       ...   \n",
      "6269   .289949  .245640  .308590  .329350   .223038   .220003   .333292   \n",
      "6270   .382000  .634750  .404550  .477790   .307628   .301921   .318646   \n",
      "6271   .370534  .245640  .458080  .477790   .445614   .443374   .339244   \n",
      "6272   .562866  .349870  .447670  .538810   .863052   .852865   .654753   \n",
      "6273   .533048  .971230  .933830  .838140   .932195   .946432   .810511   \n",
      "\n",
      "        cont14     loss  \n",
      "0     0.714843  2213.18  \n",
      "1     0.304496   1283.6  \n",
      "2     0.774425  3005.09  \n",
      "3     0.602642   939.85  \n",
      "4     0.432606  2763.85  \n",
      "...        ...      ...  \n",
      "6269   .208216  1198.62  \n",
      "6270   .305872  1108.34  \n",
      "6271   .503888  5762.64  \n",
      "6272   .721707  1562.87  \n",
      "6273   .721460  4751.72  \n",
      "\n",
      "[194592 rows x 132 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194592, 132)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.3\n",
    "\n",
    "- Define useful constants\n",
    "- Fix column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_X = [str('cat' + str(i)) for i in range(1, 117, 1)]\n",
    "CONT_X = [str('cont' + str(i)) for i in range(1, 15, 1)]\n",
    "Y = 'loss'\n",
    "\n",
    "CAT_X_Y, CONT_X_Y = CAT_X.copy(), CONT_X.copy()\n",
    "CAT_X_Y.append(Y)\n",
    "CONT_X_Y.append(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                 int32\n",
      "cat1      string[python]\n",
      "cat2      string[python]\n",
      "cat3      string[python]\n",
      "cat4      string[python]\n",
      "               ...      \n",
      "cont11           float32\n",
      "cont12           float32\n",
      "cont13           float32\n",
      "cont14           float32\n",
      "loss             float32\n",
      "Length: 132, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#basics-dtypes\n",
    "\n",
    "train_df['id']= train_df['id'].astype('int32')\n",
    "train_df['loss']= train_df['loss'].astype('float32')\n",
    "\n",
    "train_df[CAT_X]= train_df[CAT_X].astype('string')\n",
    "train_df[CONT_X]= train_df[CONT_X].astype('float32')\n",
    "\n",
    "print(train_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (B) Data Cleaning\n",
    "\n",
    "- Missing values\n",
    "- Duplicate data\n",
    "- Outliers\n",
    "- Data Quality Measures\n",
    "    - Accuracy\n",
    "    - Completeness\n",
    "    - Timeliness\n",
    "    - Believability\n",
    "    - Interoperability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1 Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     194592\n",
      "unique         1\n",
      "top        False\n",
      "freq      194592\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "null_rows = train_df.isnull().any(axis=1)\n",
    "print(null_rows.describe()) # seems to be no missing data\n",
    "\n",
    "del null_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2 Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     194592\n",
      "unique         2\n",
      "top        False\n",
      "freq      188318\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "dup_rows = train_df.duplicated()\n",
    "print(dup_rows.describe()) # no duplicates\n",
    "\n",
    "del dup_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.3 Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did not do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.4 Data Quality Measures\n",
    "- Accuracy\n",
    "- Completeness\n",
    "- Timeliness\n",
    "- Believability\n",
    "- Interoperability\n",
    "\n",
    "Not knowing what the columns are makes it hard to preform this assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (C) Graphs\n",
    "- Correlation Map\n",
    "- Boxplot\n",
    "- Histogram\n",
    "- Quantile Plot\n",
    "- Scatter Plot (correlation)\n",
    "- Mean, Median, Mode, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not doing rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Identify\n",
    "    - *Target*\n",
    "    - *Predictors* & their *Exposure*\n",
    "\n",
    "2. Visuals of *Predictors* & *Target*\n",
    "\n",
    "3. Frequency tables for *Categorical/Nominal* *Predictors*\n",
    "\n",
    "4. Start creating different models (in different notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (D) Save new DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\n",
    "    path_or_buf= os.path.join(PATH, 'code', 'v2', 'train_v2.csv'),\n",
    "    index= False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
